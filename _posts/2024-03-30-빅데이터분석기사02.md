---
title: 빅데이터 탐색 - 01 데이터 전처리
date: 2024-03-30 13:31:00 +09:00
categories: [
    Computer_Science,
    Big_Data,
]
tags: [
    CS,
    빅데이터,
    빅분기,
    기사,
]
---

## **1. 데이터의 정제**

### **1) 데이터 정제**

#### (1) 데이터 전처리
<blockquote class="custom-lightgreen">
  <p>데이터를 분석에 적합한 형태로 만드는 과정</p>
  <p>데이터 정제 - 결측값 처리 - 이상값 처리 - 분석변수 처리 순서로 진행되며, 한 번이 아닌 반복적으로 수행해야 한다.</p>
</blockquote>

#### (2) 데이터 정제

<blockquote class="custom-lightgreen">
  <p>결측값을 채우거나 이상값을 제거하는 과정을 통해 데이터의 신뢰도를 높이는 작업</p>
  <p>오류 원인 분석 - 정제 대상 선정 - 정제 방법 결정 순으로 진행된다.</p>
</blockquote> 


##### 데이터 오류 원인

| 원인  | 설명                          |
|-----|------------------------------------------------------------------|
| 결측값 | 필수적인 데이터가 입력되지 않고 누락        |
| 노이즈 | 실제론 입력되지 않았으나 입력됐다고 잘못 판단된 값            |
| 이상값 | 데이터의 범위에서 크게 벗어난 값              |

##### 데이터 정제 대상 선정

<blockquote class="custom-lightgreen">
  <p> - 모든 데이터 대상으로 정제 활동</p>
  <p> - 비정형 데이터에 대해 더 많은 정제 활동</p>
  <p> - 중복 데이터는 의미를 확인 후 제거</p>
  <p> - 원천 데이터의 위치를 기준으로 외부 데이터가 품질 저하 위협에 노출</p>
  <p> - 정형 데이터보단 비정형이나 반정형 데이터가 품질 저하 위협에 노출</p>
</blockquote>

##### 데이터 정제 방법

| 방법     | 설명                                                            |
|--------|---------------------------------------------------------------|
| 삭제     | - 오류 데이터에 대해 전체 또는 부분 삭제<br/> - 무작위적인 삭제는 데이터 활용에 지장          |
| 대체     | - 오류 데이터를 평균값, 최빈수, 중앙값 등으로 대체<br/> - 데이터 활용 시 왜곡이 발생 가능      |
| 예측값 삽입 | - 회귀식을 이용한 예측값을 생성 후 삽입<br/> - 예측값 적용 시 정상 구간에도 회귀식이 잘 적용되야 함 |
| 축소     | - 원래 가진 데이터에서 최소 단위로 만들기 위해 데이터를 제거하거나 크기를 줄임                 |
| 통합     | - 정제된 데이터를 합쳐서 데이터를 크게 만듦                                     |

##### 데이터의 일관성 유지를 위한 기법

| 기법 | 설명        |
|----|-----------|
| 변환 | 일관된 형태로 변환 |
| 파싱 | 최소단위로 분할  |
| 보강 | 추가 정보를 반영 |


#### (3) 데이터 세분화
<blockquote class="custom-lightgreen">
  <p>데이터를 기준에 따라 나누고 그룹화 하는 프로세스</p>
  <p>계층적 방법(응집분석, 분할분석)과 비계층적 방법(인공신경망, k평균)으로 구분</p>
</blockquote>

### **2) 데이터 결측값 처리**

#### (1) 데이터 결측값 종류(3가지)

| 종류        | 설명                               |
|-----------|----------------------------------|
| 완전 무작위 결측 | - 결측값이 다른 변수들과 아무런 상관이 없음        |
| 무작위 결측    | - 결측값이 특정 변수와 관련은 있으나 결과는 관계가 없음 |
| 비 무작위 결측  | - 결측값이 다른 변수와 연관이 있음             |

#### (2) 데이터 결측값 처리 방법

- 단순 대치법

| 종류        | 설명                                                            |
|-----------|---------------------------------------------------------------|
| 완전 분석법    | 완전하게 관측된 자료만 분석에 사용                                           |
| 평균 대치법    | 평균값으로 결측값을 대치                                                 |
| 단순 확률 대치법 | 추정된 통계량으로 결측값을 대치할 때 적절한 확률값을 부여한 뒤 대치    <br/> 핫덱 / 콜드덱 / 혼합 |
| 회귀 대치법    | 결측값이 포함된 변수를 종속변수로 회귀 분석 진행 후 얻은 추정값으로 대치                     |

- 다중 대치법
  - 단순 대치법을 n번 진행한 뒤 얻은 n개의 가상 자료로 분석
  - 대치(n개의 자료 생성) - 분석(추정값, 표준오차 계산) - 결합(최종 결측값 획득) 순서로 진행


### **3) 데이터 이상값 처리**

#### (1) 데이터 이상값 발생 원인(7가지)

- 표본 추출의 오류
- 고의적인 이상값
- 데이터 입력 오류
- 실험 오류
- 측정 오류
- 데이터 처리 오류
- 자연 오류

#### (2) 데이터 이상값 검출 방법

- 통계 기법을 이용한 데이터 이상값 검출
  - ESD(Extreme Studentized Deviation): 평균에서 3 표준편차 떨어진 값
  - 기하평균에서 2.5 표준편차 떨어진 값
  - 사분위 간 범위의 1.5배 이상 떨어진 값
  - Z점수: 정규분포 관측치가 평균에서 얼마나 떨어져 있는가
  - 딕슨의 Q검정: 데이터 30개 미만, 오름차순 정렬 데이터에서 관측치간 차이의 비율로 검정
  - 그럽스 T검정: 정규분포 만족 단변량 자료에서 검정
  - 카이제곱 검정: 데이터가 적은 정규분포 만족 데이터
  - 마할라노비스 거리
- 시각화를 이용한 데이터 이상값 검출
  - 확률 밀도 함수
  - 히스토그램
  - 시계열 차트
- 데이터 군집 / 분류를 통한 데이터 이상값 검출
  - K-평균 군집: k개의 클러스터로 묶은 뒤 각 클러스터 거리 차의 분산을 최소화
  - LOF(Local Outlier Factor): LOF가 클 수록 이상값 큼
  - iForest(Isolation Forest): 의사결정나무 이용, 적은 횟수로 잎노드에 도달하는 애가 이상값 확률 높음

#### (3) 데이터 이상값 처리

  - 삭제
  - 대체
  - 변환

### **4) 텍스트 전처리**

  - 토큰화(Tokenization)
  - 품사 태깅(POS Tagging)
  - 표제어 추출
  - 어간 추출
  - 불용어 처리

## **2. 분석 변수 처리**

### **1) 변수 선택**

<blockquote class="custom-lightblue">
  <p>데이터의 독립변수 중 종속변수에 관련성이 높은 변수만을 선정</p>
  <p>필터 / 래퍼 / 임베디드의 3가지 기법</p>
  <p>모델 단순화 / 훈련 시간 축소 / 차원 저주 방지 / 과적합 방지를 통한 모델의 정확도 및 성능 향상</p>
  <p>비지도 방식과 지도 방식으로 구분</p>
</blockquote>

#### 필터 기법
#### 래퍼 기법
#### 임베디드 기법

### **2) 차원 축소**

<blockquote class="custom-lightblue">
  <p>분석 대상인 변수들의 정보를 최대한 유지하면서 데이터 세트 변수의 개수를 줄임</p>
  <p>종속변수는 사용하지 않고 독립변수만 사용하는 비지도 학습 머신러닝 기법</p>
  <p>많은 차원으로 이루어진 데이터에 주로 사용</p>
</blockquote>

  - 주성분 분석(PCA)
  - 특이값 분해(SVD)
  - 요인 분석()
  - 독립 성분 분석()
  - 다차원 척도법()


### **3) 파생변수 생성**

  - 단위 변환
  - 표현 형식 변환
  - 요약 통계량 변환
  - 정보 추출
  - 변수 결합
  - 조건문 이용

#### 인코딩

  - 원-핫 인코딩
  - 레이블 인코딩
  - 카운트 인코딩
  - 대상 인코딩

### **4) 변수 변환**

<blockquote class="custom-lightblue">
  <p>선형관계가 아닌 변수에 대한 선형화 변형 작업</p>
  <p>로그, 지수, 제곱 등의 변수 관계일 때 분석의 편의를 높이기 위해 사용</p>
</blockquote>

  - 박스-콕스 변환(Box-Cox Transformation)
  - 비닝(Binning)
  - 정규화(Nomalizaiton)
    - 최소 최대 정규화(Min-Max)
    - Z점수 정규화, 표준화(Z-score, Standardizaion)
    - 분위수 정규화(Quantile)


### **5) 불균형 데이터 처리**

<blockquote class="custom-lightblue">
  <p>한 클래스의 샘플 수가 다른 클래스에 비해 적을 때 모델의 성능 확보를 위해 사용</p>
  <p>F1 지표, 정밀도, 재현율, AUC를 활용해 성능 평가</p>
</blockquote>

  - 과소 표집(Under-Sampling)
  - 과대 표집(Over-Sampling)
  - 임곗값 이동(Cutoff Value Moving)
  - 비용 민감 학습(Cost Sensitive Learning)
  - 앙상블 기법(Ensemble Technique)

